---
title: "03-Dataset and Simulations"
output:
  pdf_document: default
  html_document: default
---


# Deduplication Process:

The dedeuplication process elaborated herein involves the following steps:

*  Comparing variables across multiple records and identifying similar ones  
*  Identify potential pairs of records that are similar  
*  Assign weights to each pair based on weights  
*  Identify a lower and higher threshold across which the records will be considered unique or identical pairs.  The middle region will be potential ones that needs to be further classified  

*  Classification can be achieved manually  
*  Classification can be done using a classifier that can be tuned using a training set created clerically  
*  As an alternative to the above, the classifier can be created using Machine Learning algorithms  

The figure illustrates the process:

 <center>![Deduplication Process](classification-process.png)</center>


##Summary of Results:

Number of duplicate records :  `r nrow(changes.ds)`  


```{r, message=FALSE, warning=FALSE, include=FALSE}
rpairs <- compare.dedup(new.base.ds, blockfld=list(4),
                        phonetic=(3:4),
                        exclude = c("record.id","birth.date"))
#drop birth.date before bulding comparion pairs

```

The weight distribution with number of records under the range is shown in the table below:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
rpairs <- epiWeights(rpairs)
suppressPackageStartupMessages(library(pander))
panderOptions("table.split.table", Inf)  ## don't split tables
pander(summary(rpairs)[1:2])

```



##Classification of Records based on Unsupervised Classification:

The following is the output of an unsupervised classification done using "kmeans" classification algorithm:  


```{r, echo=FALSE, message=FALSE, warning=FALSE}
classified.ds <- classifyUnsup(rpairs, method="kmeans")
summary(classified.ds)
```

The difference between the duplicates we created and the identified linkages denotes the error from the deduplication process.


###Manual  Classification

It is possible to classify the records using thresholds identified manually.  In the controlled experiment, the following thresholds give exactly the same value as unsupervised classification:  

Higher value = 0.85 (Anything beyond this does not impact the classification output)   
Lower value  = 0.40 (This value determines whether the classification is optimistic or pessimistic)   

The output of the above threshold values is given below:  


```{r, echo=FALSE, message=FALSE, warning=FALSE}
result <- epiClassify(rpairs, 0.85,0.40)
summary(result)
```


###Pessimistic Thresholds
It is advised to adopt a pessimistic approach while identifying threshold values since probable ones could be verified clerically to avoid false positives:  

We get a pessimistic value from the manual process.  This avoids the problem of false positives.  The manually selected threshold is further validated on a larger population of the dataset with:  

*  More number of records
*  Varied data quality range


##Notes:

###Build Comparison Patterns

The component patterns are built as component pairs.  The row numbers of the underlying records are followed by their comparison vector.  The column is_match shows the matching status of a pair: '0' stands for non-match, 1 means, match.  

While doing comparison, certain fields are such as, the First Name and Last Name values are checked for their phonetic equivalents; thereby overcoming spelling anomalies.  

Additionally, columns "record.id" and "birth.date" are excluded from comparison since these are control data: used only for reference purpose.  The date of birth is broken up into date, month and year and further compared.


