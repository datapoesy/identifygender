---
title: "05-Classification Experiment"
output:
  pdf_document: default
  html_document: default
---


#Supervised Machine Learning:

##Supervised classification with minimal pairs

This chapter conducts an experiment on supervised classification with labeled examples.  The other classification methods are ignored since supervised training has been providing consistent results throughout the experiment.

No of records to de-duplicated - 5000  
quality rating is 76%  


###Preparing a Minimal training set using clerical means

* A training set prepared from paired data minimally represents all unique scenarios in the data set.
* This is prepared clerically, by comparing pairs from the minimal set and labelling their match, denoting it with "1" if a match and "0", if otherwise.
* This is labeled to show whether a pair is a match in terms of records.  The is_match column against a record pair clerically confirms a pair match.
* The training set used for these experiments is prepared from a base data set of 20,000 records and has labeled record of 503 pairs.

<span><center> !["Sample Training Set"](image/sample-training-set.png){width=100% }</center>
<h4><center>Figure.4.1 Sample Training Set</center></h4> </span>
 





```{r chapter 5-1, echo=FALSE, message=FALSE, warning=FALSE}


###Supervised clasification with Minimal Training Set

panderOptions("table.split.table", Inf)  ## don't split tables

read.cl.results.00 <- read.csv (file="cl.results.00.csv")
read.cl.results.00 <- read.cl.results.00[,-c(1,6,10)]
colnames(read.cl.results.00) <- c("No.","Total\n.Records","Duplicates","Non\n.Duplicates","Record\n.Pairs","Quality\n.Perc","Ident\n.Pairs")

pander(read.cl.results.00, caption="Supervised Classification using Minimal Training Set", short= TRUE, split.tables=200,keep.line.breaks = TRUE)

```


##The pairs identified as duplicates by the Classifier (top few):

The followign table shows 5 top records that has been identified by the classifier as duplicates.  The classifier has picked the records that had been tagged as duplicates.

The record id, say '90390' and '90390 D' refers to the original record and the duplicate created as part of the data "debasement" process, respectively.

```{r chapter 5-2, echo=FALSE, message=FALSE, warning=FALSE}
panderOptions('table.alignment.default','left')
head.ident.pairs.00 <- head(ident.pairs.00)
head.ident.pairs.00.a <- head.ident.pairs.00[,c(1:6)]
head.ident.pairs.00.b <- head.ident.pairs.00[,c(7:12)]
head.ident.pairs.00.c <- head.ident.pairs.00[,c(13:20)]
pander(head.ident.pairs.00.a, caption="Duplicates identified by dedup engine", short= TRUE, split.tables=180, split.cells = c(20,30,40,40,20,30),keep.line.breaks = TRUE)
pander(head.ident.pairs.00.b, caption="Duplicates identified by dedup engine ...contd", short= TRUE, split.tables=180, split.cells = c(20,30,40,40,20,30),keep.line.breaks = TRUE)
pander(head.ident.pairs.00.c, caption="Duplicates identified by dedup engine ...contd", short= TRUE, split.tables=180, split.cells = c(20,30,40,40,20,30,30),keep.line.breaks = TRUE)

remove(head.ident.pairs.00,head.ident.pairs.00.a,head.ident.pairs.00.b,head.ident.pairs.00.c)
```

Note that all records identified have been tagged with "D" identifying the exact duplicates.


##The last few records identified as pairs (False Positives)

The false positives are listed at the end of the results.  In a pessimistic pairing approach, there will not be any false positives.

Note that the lower weight threshold limit is closer to the optimal threshold selected by the unsupervised algorith.  However, it cannot handle unique scenarios, otherwise managed by a training set.

`
```{r chapter 5-3, echo=FALSE, message=FALSE, warning=FALSE}
panderOptions('table.alignment.default','left')
tail.ident.pairs.00 <- tail(ident.pairs.00)
rownames(tail.ident.pairs.00) <- NULL
tail.ident.pairs.00 <- tail.ident.pairs.00[, -c(1)]
colnames(tail.ident.pairs.00) <- c("Record\n.id","some\n.id","firstname","lastname","gender",
                                   "birth\n.date","email","m.number","h.number",
                                   "addr.1","addr.2","cityname", "postcode","county","nis",
                                   "b.year","b.month","b.day","Weight")
tail.ident.pairs.00.a <- tail.ident.pairs.00[,c(1:6)]
tail.ident.pairs.00.b <- tail.ident.pairs.00[,c(7:12)]
tail.ident.pairs.00.c <- tail.ident.pairs.00[,c(13:19)]

pander(tail.ident.pairs.00.a, caption="False positives from the dedup process", short= TRUE, split.tables=180, split.cells = c(20,30,40,40,20,30),keep.line.breaks = TRUE)
pander(tail.ident.pairs.00.b, caption="False positives from the dedup process ...contd", short= TRUE, split.tables=180, split.cells = c(20,30,40,40,20,30),keep.line.breaks = TRUE)
pander(tail.ident.pairs.00.c, caption="False positives from the dedup process ...contd", short= TRUE, split.tables=180, split.cells = c(20,30,40,40,20,30,30),keep.line.breaks = TRUE)

remove(tail.ident.pairs.00,tail.ident.pairs.00.a,tail.ident.pairs.00.b,tail.ident.pairs.00.c)
```



